# HandTalk_Decoder

HandTalk Decoder is an AI-driven system designed to translate sign language gestures into text in real-time. It uses computer vision and natural language processing techniques to bridge the communication gap between sign language users and non-sign language users. The project aims to support multiple sign languages, ensure affordability, and provide accessible learning tools for greater inclusivity. With features like real-time gesture recognition,and  interactive educational modules, HandTalk Decoder fosters seamless and inclusive communication.

Following are the steps to implement the project:

1. Make sure you are using python version < 3.11

2. Create a virtual environment >> python -m venv myenv 

3. Activate myenv >> myenv\Scripts\activate

4. Install required packages >> pip install opencv cvzone mediapipe tenserflow

5. Now run the python file.
